{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import openTSNE\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torchvision\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../scripts\")\n",
    "from data import SmallPatchesDataset, get_filenames_center_blocks\n",
    "from models import AutoEncoderResnetExtractor, DEC\n",
    "import preprocessing_census_blocks\n",
    "\n",
    "# autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cities_used = 100\n",
    "\n",
    "# remove patches that are have small intersection with block\n",
    "intersection_threshold = 0.25\n",
    "\n",
    "# remove patches from blocks that have more than a threshold \n",
    "patches_count_max = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "blocks_df = pd.read_csv(\"../data/blocks_patches_relation.csv\")\n",
    "blocks_df[\"mhi\"] = blocks_df[\"mhi\"].apply(lambda x: np.nan if x < 0 else x)\n",
    "blocks_df = blocks_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace negative mhi with nan\n",
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "blocks_df[\"clean_patches_relation\"] = blocks_df.patches_relation.apply(literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "blocks_df[\"n_patches\"] = blocks_df.clean_patches_relation.apply(lambda x : len(x))\n",
    "blocks_df = blocks_df[blocks_df.n_patches > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_patches_relation(s):\n",
    "    filenames = []\n",
    "    data = []\n",
    "    for key, value in s.items():\n",
    "        value = np.array(value)\n",
    "        value = value[value[:, 1] > intersection_threshold, :]\n",
    "        for i in range(len(value)):\n",
    "            data.append(value[i, :])\n",
    "            filenames.append(key)\n",
    "    data = np.array(data)\n",
    "\n",
    "    if len(filenames) > patches_count_max:\n",
    "        selected = np.random.choice(\n",
    "            len(filenames),\n",
    "            size=patches_count_max,\n",
    "            replace=False,\n",
    "            p=data[:, 1] / data[:, 1].sum(),\n",
    "        )\n",
    "        data = data[selected, :]\n",
    "        filenames = [filenames[i] for i in selected]\n",
    "    return [f\"{filenames[i]} {int(data[i, 0])}\" for i in range(len(filenames))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "blocks_df[\"clean_patches_relation\"] = blocks_df.clean_patches_relation.apply(\n",
    "    clean_patches_relation\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['seattle_wa/2862468_m_4712223_nw_10_060_20191011_1197.png 2',\n",
       " 'seattle_wa/2862468_m_4712223_nw_10_060_20191011_1009.png 1',\n",
       " 'seattle_wa/2862468_m_4712223_nw_10_060_20191011_1159.png 3',\n",
       " 'seattle_wa/2862468_m_4712223_nw_10_060_20191011_1313.png 0',\n",
       " 'seattle_wa/2862468_m_4712223_nw_10_060_20191011_1162.png 1',\n",
       " 'seattle_wa/2862468_m_4712223_nw_10_060_20191011_1084.png 2',\n",
       " 'seattle_wa/2862468_m_4712223_nw_10_060_20191011_1123.png 2',\n",
       " 'seattle_wa/2862468_m_4712223_nw_10_060_20191011_1121.png 2',\n",
       " 'seattle_wa/2862468_m_4712223_nw_10_060_20191011_1276.png 3',\n",
       " 'seattle_wa/2862468_m_4712223_nw_10_060_20191011_1161.png 1',\n",
       " 'seattle_wa/2862468_m_4712223_nw_10_060_20191011_1047.png 0',\n",
       " 'seattle_wa/2862468_m_4712223_nw_10_060_20191011_1160.png 3',\n",
       " 'seattle_wa/2862468_m_4712223_nw_10_060_20191011_1161.png 2',\n",
       " 'seattle_wa/2862468_m_4712223_nw_10_060_20191011_971.png 2',\n",
       " 'seattle_wa/2862468_m_4712223_nw_10_060_20191011_1314.png 2',\n",
       " 'seattle_wa/2862468_m_4712223_nw_10_060_20191011_1314.png 1',\n",
       " 'seattle_wa/2862468_m_4712223_nw_10_060_20191011_1200.png 0',\n",
       " 'seattle_wa/2862468_m_4712223_nw_10_060_20191011_1197.png 3',\n",
       " 'seattle_wa/2862468_m_4712223_nw_10_060_20191011_1010.png 3',\n",
       " 'seattle_wa/2862468_m_4712223_nw_10_060_20191011_1313.png 1',\n",
       " 'seattle_wa/2862468_m_4712223_nw_10_060_20191011_1313.png 2',\n",
       " 'seattle_wa/2862468_m_4712223_nw_10_060_20191011_1199.png 3',\n",
       " 'seattle_wa/2862468_m_4712223_nw_10_060_20191011_1086.png 3',\n",
       " 'seattle_wa/2862468_m_4712223_nw_10_060_20191011_1086.png 1',\n",
       " 'seattle_wa/2862468_m_4712223_nw_10_060_20191011_1236.png 0',\n",
       " 'seattle_wa/2862468_m_4712223_nw_10_060_20191011_1008.png 3',\n",
       " 'seattle_wa/2862468_m_4712223_nw_10_060_20191011_1124.png 3',\n",
       " 'seattle_wa/2862468_m_4712223_nw_10_060_20191011_1010.png 0',\n",
       " 'seattle_wa/2862468_m_4712223_nw_10_060_20191011_1048.png 3',\n",
       " 'seattle_wa/2862468_m_4712223_nw_10_060_20191011_1276.png 1',\n",
       " 'seattle_wa/2862468_m_4712223_nw_10_060_20191011_1046.png 1',\n",
       " 'seattle_wa/2862468_m_4712223_nw_10_060_20191011_1351.png 2',\n",
       " 'seattle_wa/2862468_m_4712223_nw_10_060_20191011_1235.png 1',\n",
       " 'seattle_wa/2862468_m_4712223_nw_10_060_20191011_1121.png 1',\n",
       " 'seattle_wa/2862468_m_4712223_nw_10_060_20191011_1159.png 0',\n",
       " 'seattle_wa/2862468_m_4712223_nw_10_060_20191011_1350.png 0',\n",
       " 'seattle_wa/2862468_m_4712223_nw_10_060_20191011_1009.png 0',\n",
       " 'seattle_wa/2862468_m_4712223_nw_10_060_20191011_1351.png 1',\n",
       " 'seattle_wa/2862468_m_4712223_nw_10_060_20191011_1122.png 3',\n",
       " 'seattle_wa/2862468_m_4712223_nw_10_060_20191011_1009.png 3',\n",
       " 'seattle_wa/2862468_m_4712223_nw_10_060_20191011_1008.png 0',\n",
       " 'seattle_wa/2862468_m_4712223_nw_10_060_20191011_1236.png 1',\n",
       " 'seattle_wa/2862468_m_4712223_nw_10_060_20191011_1197.png 0',\n",
       " 'seattle_wa/2862468_m_4712223_nw_10_060_20191011_1123.png 0',\n",
       " 'seattle_wa/2862468_m_4712223_nw_10_060_20191011_1352.png 1',\n",
       " 'seattle_wa/2862468_m_4712223_nw_10_060_20191011_1162.png 0',\n",
       " 'seattle_wa/2862468_m_4712223_nw_10_060_20191011_1200.png 1',\n",
       " 'seattle_wa/2862468_m_4712223_nw_10_060_20191011_970.png 0',\n",
       " 'seattle_wa/2862468_m_4712223_nw_10_060_20191011_1124.png 2',\n",
       " 'seattle_wa/2862468_m_4712223_nw_10_060_20191011_1047.png 3',\n",
       " 'seattle_wa/2862468_m_4712223_nw_10_060_20191011_1275.png 3',\n",
       " 'seattle_wa/2862468_m_4712223_nw_10_060_20191011_1315.png 3',\n",
       " 'seattle_wa/2862468_m_4712223_nw_10_060_20191011_1010.png 2',\n",
       " 'seattle_wa/2862468_m_4712223_nw_10_060_20191011_1159.png 2',\n",
       " 'seattle_wa/2862468_m_4712223_nw_10_060_20191011_1198.png 3',\n",
       " 'seattle_wa/2862468_m_4712223_nw_10_060_20191011_1198.png 2',\n",
       " 'seattle_wa/2862468_m_4712223_nw_10_060_20191011_1047.png 1',\n",
       " 'seattle_wa/2862468_m_4712223_nw_10_060_20191011_1197.png 1',\n",
       " 'seattle_wa/2862468_m_4712223_nw_10_060_20191011_1085.png 3',\n",
       " 'seattle_wa/2862468_m_4712223_nw_10_060_20191011_1085.png 2',\n",
       " 'seattle_wa/2862468_m_4712223_nw_10_060_20191011_1238.png 1',\n",
       " 'seattle_wa/2862468_m_4712223_nw_10_060_20191011_1350.png 3',\n",
       " 'seattle_wa/2862468_m_4712223_nw_10_060_20191011_1352.png 3',\n",
       " 'seattle_wa/2862468_m_4712223_nw_10_060_20191011_1161.png 0',\n",
       " 'seattle_wa/2862468_m_4712223_nw_10_060_20191011_1312.png 0',\n",
       " 'seattle_wa/2862468_m_4712223_nw_10_060_20191011_1235.png 2',\n",
       " 'seattle_wa/2862468_m_4712223_nw_10_060_20191011_1314.png 0',\n",
       " 'seattle_wa/2862468_m_4712223_nw_10_060_20191011_1275.png 2',\n",
       " 'seattle_wa/2862468_m_4712223_nw_10_060_20191011_1199.png 2',\n",
       " 'seattle_wa/2862468_m_4712223_nw_10_060_20191011_1199.png 0',\n",
       " 'seattle_wa/2862468_m_4712223_nw_10_060_20191011_1198.png 0',\n",
       " 'seattle_wa/2862468_m_4712223_nw_10_060_20191011_1237.png 0',\n",
       " 'seattle_wa/2862468_m_4712223_nw_10_060_20191011_1312.png 1',\n",
       " 'seattle_wa/2862468_m_4712223_nw_10_060_20191011_1121.png 3',\n",
       " 'seattle_wa/2862468_m_4712223_nw_10_060_20191011_1351.png 3',\n",
       " 'seattle_wa/2862468_m_4712223_nw_10_060_20191011_1238.png 3',\n",
       " 'seattle_wa/2862468_m_4712223_nw_10_060_20191011_1162.png 3',\n",
       " 'seattle_wa/2862468_m_4712223_nw_10_060_20191011_1084.png 0',\n",
       " 'seattle_wa/2862468_m_4712223_nw_10_060_20191011_1086.png 2',\n",
       " 'seattle_wa/2862468_m_4712223_nw_10_060_20191011_1275.png 1',\n",
       " 'seattle_wa/2862468_m_4712223_nw_10_060_20191011_1314.png 3',\n",
       " 'seattle_wa/2862468_m_4712223_nw_10_060_20191011_1084.png 1',\n",
       " 'seattle_wa/2862468_m_4712223_nw_10_060_20191011_1313.png 3',\n",
       " 'seattle_wa/2862468_m_4712223_nw_10_060_20191011_1048.png 0',\n",
       " 'seattle_wa/2862468_m_4712223_nw_10_060_20191011_1159.png 1',\n",
       " 'seattle_wa/2862468_m_4712223_nw_10_060_20191011_1008.png 2',\n",
       " 'seattle_wa/2862468_m_4712223_nw_10_060_20191011_1123.png 1',\n",
       " 'seattle_wa/2862468_m_4712223_nw_10_060_20191011_1274.png 1',\n",
       " 'seattle_wa/2862468_m_4712223_nw_10_060_20191011_1086.png 0',\n",
       " 'seattle_wa/2862468_m_4712223_nw_10_060_20191011_1160.png 1',\n",
       " 'seattle_wa/2862468_m_4712223_nw_10_060_20191011_1008.png 1',\n",
       " 'seattle_wa/2862468_m_4712223_nw_10_060_20191011_1161.png 3',\n",
       " 'seattle_wa/2862468_m_4712223_nw_10_060_20191011_1046.png 2',\n",
       " 'seattle_wa/2862468_m_4712223_nw_10_060_20191011_1084.png 3',\n",
       " 'seattle_wa/2862468_m_4712223_nw_10_060_20191011_1122.png 1',\n",
       " 'seattle_wa/2862468_m_4712223_nw_10_060_20191011_1201.png 3',\n",
       " 'seattle_wa/2862468_m_4712223_nw_10_060_20191011_1121.png 0',\n",
       " 'seattle_wa/2862468_m_4712223_nw_10_060_20191011_971.png 0',\n",
       " 'seattle_wa/2862468_m_4712223_nw_10_060_20191011_1237.png 3',\n",
       " 'seattle_wa/2862468_m_4712223_nw_10_060_20191011_1048.png 2']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blocks_df.clean_patches_relation.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "blocks_df = gpd.read_file(\"../data/census_blocks_patches_v2.geojson\")\n",
    "\n",
    "# filtering to test with some blocks, selecting the cities with the biggest number of blocks\n",
    "biggest_blocks = blocks_df.groupby([\"state\", \"county\"]).agg(\"count\").reset_index().iloc[:, 0:3].sort_values(\"tract\", ascending = False).head(n_cities_used)\n",
    "blocks_df = blocks_df[(blocks_df.state.isin(biggest_blocks.state) & blocks_df.county.isin(biggest_blocks.county))]\n",
    "\n",
    "# cleaning blocks with missing data\n",
    "blocks_df = blocks_df[blocks_df.mhi > 0]\n",
    "blocks_df = blocks_df.dropna()\n",
    "blocks_df = blocks_df[blocks_df.patches_relation.apply(len) > 0]\n",
    "\n",
    "blocks_df[\"area_km2\"] = blocks_df['geometry'].to_crs({'proj':'cea'}).area / 10**6\n",
    "blocks_df[\"density\"] = blocks_df[\"pop\"] / blocks_df[\"area_km2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "blocks_id = preprocessing_census_blocks.get_locations_info()\n",
    "blocks_id = blocks_id.merge(\n",
    "    preprocessing_census_blocks.get_states_codes(),\n",
    "    left_on = \"state\",\n",
    "    right_on = \"state_abbr\",\n",
    ")\n",
    "blocks_id[\"state\"] = blocks_id[\"state_x\"]\n",
    "blocks_id = blocks_id.drop([\"state_x\", \"state_y\", \"year\", \"state_abbr\"], axis = 1)\n",
    "blocks_id[\"city_state\"] = blocks_id[\"city\"] + \"_\" + blocks_id[\"state\"]\n",
    "blocks_df[\"state_abbr\"] = blocks_df[\"state\"].apply(lambda x : blocks_id[blocks_id.state_code == x].state.values[0])\n",
    "blocks_df[\"city_name\"] = blocks_df.apply(lambda x : blocks_id[(blocks_id.state_code == x.state) & (blocks_id.county_codes.str.find(x.county) >= 0)].city.values[0], axis = 1)\n",
    "blocks_df[\"city_state\"] = blocks_df[\"city_name\"] + \"_\" + blocks_df[\"state_abbr\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_patches_relation(s):\n",
    "    s = s.split(\"\\n\")\n",
    "    s = dict([x.split(\":\") for x in s])\n",
    "    filenames = []\n",
    "    data = []\n",
    "    for key, value in s.items():\n",
    "        value = value.split(\" \")\n",
    "        idx = np.array([float(v) for v in value[0].split(\",\")])\n",
    "        ratio = np.array([float(v) for v in value[1].split(\",\")])\n",
    "        idx = idx[ratio > intersection_threshold]\n",
    "        ratio = ratio[ratio > intersection_threshold]\n",
    "        for i in range(len(idx)):\n",
    "            data.append([idx[i], ratio[i]])\n",
    "            filenames.append(key)\n",
    "    data = np.array(data)\n",
    "    if len(filenames) > patches_count_max:\n",
    "        selected = np.random.choice(\n",
    "            len(filenames),\n",
    "            size=patches_count_max,\n",
    "            replace=False,\n",
    "            p=data[:, 1] / data[:, 1].sum(),\n",
    "        )\n",
    "        data = data[selected, :]\n",
    "        filenames = [filenames[i] for i in selected]\n",
    "    return [filenames, data]\n",
    "\n",
    "blocks_df[\"clean_patches_relation\"] = blocks_df.patches_relation.apply(\n",
    "    clean_patches_relation\n",
    ")\n",
    "blocks_df[\"n_patches\"] = blocks_df[\"clean_patches_relation\"].apply(\n",
    "    lambda x: x[1].shape[0]\n",
    ")\n",
    "blocks_df = blocks_df[blocks_df.n_patches > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "blocks_df = blocks_df.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique patches: 3655529\n"
     ]
    }
   ],
   "source": [
    "patches_blocks = {}\n",
    "for i, row in blocks_df.iterrows():\n",
    "    relation_list = row[\"patches_relation\"].strip(\" \").split(\" \")\n",
    "    relation_list = [x.split(\";\") for x in relation_list]\n",
    "    relation_list = row[\"clean_patches_relation\"][0]\n",
    "    idx = row[\"clean_patches_relation\"][1][:, 0]\n",
    "    files = [f\"{relation_list[j]} {int(idx[j])}\" for j in range(len(relation_list))]\n",
    "    for file in files:\n",
    "        if file in patches_blocks.keys():\n",
    "            patches_blocks[file].append(i)\n",
    "        else:\n",
    "            patches_blocks[file] = [i]\n",
    "print(f\"Number of unique patches: {len(patches_blocks.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = AutoEncoderResnetExtractor(128)\n",
    "model.load_state_dict(torch.load(\"../models/AE_extractor_resnet50_small_128/model.pt\"))\n",
    "model.to(device);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering a subset of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames_subset = get_filenames_center_blocks()\n",
    "dataset_subset = SmallPatchesDataset(filenames_subset, resize = (224, 224))\n",
    "dl_subset = torch.utils.data.DataLoader(dataset_subset, batch_size = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1789 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1789/1789 [35:27<00:00,  1.19s/it]\n"
     ]
    }
   ],
   "source": [
    "embeddings = []\n",
    "with torch.no_grad():\n",
    "    for x in tqdm(dl_subset):\n",
    "        x = x.to(device)\n",
    "        embeddings.append(model.encoder(x).cpu().numpy())\n",
    "embeddings = np.concatenate(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 50\n",
    "kmeans = KMeans(\n",
    "    n_clusters = k, \n",
    "    random_state = 0, \n",
    "    n_init = 20\n",
    ").fit(embeddings)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = list(patches_blocks.keys())\n",
    "dataset = SmallPatchesDataset(filenames, resize = (224, 224))\n",
    "dl = torch.utils.data.DataLoader(dataset, batch_size = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clusters(dl, model, kmeans):\n",
    "    device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "    clusters = []\n",
    "    clusters_distance = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dl):\n",
    "            batch = batch.to(device)\n",
    "            z = model.encoder(batch).detach().cpu().numpy()\n",
    "            c = kmeans.predict(z)\n",
    "            d = kmeans.transform(z)\n",
    "            clusters.append(c)\n",
    "            clusters_distance.append(d)\n",
    "\n",
    "    clusters = np.concatenate(clusters)\n",
    "    clusters_distance = np.concatenate(clusters_distance)\n",
    "    return clusters, clusters_distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/12186 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12186/12186 [3:29:14<00:00,  1.03s/it] \n"
     ]
    }
   ],
   "source": [
    "clusters, clusters_distance = get_clusters(dl, model, kmeans)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to generate block features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to generate features from model output\n",
    "def count_of_patches_cluster():\n",
    "    x = np.zeros((blocks_df.shape[0], k))\n",
    "    for i, (file, cluster) in enumerate(zip(filenames, clusters)):\n",
    "        for b in patches_blocks[file]:\n",
    "            x[b, cluster] += 1\n",
    "    x = pd.DataFrame(x, columns = [f\"cluster_{i}\" for i in range(k)])\n",
    "    x = x.loc[:, x.sum(axis = 0) > 0]\n",
    "    return x\n",
    "\n",
    "def fraction_of_patches_cluster():\n",
    "    x = np.zeros((blocks_df.shape[0], k))\n",
    "    for i, (file, cluster) in enumerate(zip(filenames, clusters)):\n",
    "        for b in patches_blocks[file]:\n",
    "            x[b, cluster] += 1\n",
    "    x_sum = x.sum(axis = 1)\n",
    "    x = x / x_sum[:, None]\n",
    "    x = pd.DataFrame(x, columns = [f\"cluster_{i}\" for i in range(k)])\n",
    "    x = x.loc[:, x.sum(axis = 0) > 0]\n",
    "    x[\"count\"] = x_sum\n",
    "    return x\n",
    "\n",
    "def fraction_of_patches_cluster_coords():\n",
    "    x = np.zeros((blocks_df.shape[0], k))\n",
    "    for i, (file, cluster) in enumerate(zip(filenames, clusters)):\n",
    "        for b in patches_blocks[file]:\n",
    "            x[b, cluster] += 1\n",
    "    x_sum = x.sum(axis = 1)\n",
    "    x = x / x_sum[:, None]\n",
    "    x = pd.DataFrame(x, columns = [f\"cluster_{i}\" for i in range(k)])\n",
    "    x = x.loc[:, x.sum(axis = 0) > 0]\n",
    "    x[\"count\"] = x_su\n",
    "    x[\"x\"] = blocks_df.geometry.centroid.x\n",
    "    x[\"y\"] = blocks_df.geometry.centroid.y\n",
    "    return x\n",
    "\n",
    "def distance_of_patches_cluster():\n",
    "    x = np.zeros((blocks_df.shape[0], k))\n",
    "    for i, (file, distances) in enumerate(zip(filenames, clusters_distance)):\n",
    "        for b in patches_blocks[file]:\n",
    "            x[b] += distances\n",
    "    x_sum = blocks_df.n_patches.values.reshape(-1)\n",
    "    x = x / x_sum[:, None]\n",
    "    x = pd.DataFrame(x, columns = [f\"cluster_{i}\" for i in range(k)])\n",
    "    x = x.loc[:, x.sum(axis = 0) > 0]\n",
    "    x[\"count\"] = x_sum\n",
    "    return x\n",
    "\n",
    "def distance_of_patches_cluster_coords():\n",
    "    x = np.zeros((blocks_df.shape[0], k))\n",
    "    for i, (file, distances) in enumerate(zip(filenames, clusters_distance)):\n",
    "        for b in patches_blocks[file]:\n",
    "            x[b] += distances\n",
    "    x_sum = blocks_df.n_patches.values.reshape(-1)\n",
    "    x = x / x_sum[:, None]\n",
    "    x = pd.DataFrame(x, columns = [f\"cluster_{i}\" for i in range(k)])\n",
    "    x = x.loc[:, x.sum(axis = 0) > 0]\n",
    "    x[\"count\"] = x_sum\n",
    "    x[\"x\"] = blocks_df.geometry.centroid.x\n",
    "    x[\"y\"] = blocks_df.geometry.centroid.y\n",
    "    return x\n",
    "\n",
    "def get_x(method):\n",
    "    if method == \"count\":\n",
    "        return count_of_patches_cluster()\n",
    "    elif method == \"fraction\":\n",
    "        return fraction_of_patches_cluster()\n",
    "    elif method == \"fraction_coords\":\n",
    "        return fraction_of_patches_cluster_coords()\n",
    "    elif method == \"distance\":\n",
    "        return distance_of_patches_cluster()\n",
    "    elif method == \"distance_coords\":\n",
    "        return distance_of_patches_cluster_coords()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training all the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(clf, x_train, y_train, x_test, y_test):\n",
    "    r2_train = r2_score(y_train, clf.predict(x_train))\n",
    "    r2_test = r2_score(y_test, clf.predict(x_test))\n",
    "    return r2_train, r2_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_rf(x_train, y_train, x_test, y_test):\n",
    "    rf = RandomForestRegressor()\n",
    "    parameters = {\n",
    "        \"n_estimators\": [10, 100, 1000],\n",
    "        \"max_depth\": [10, 25],\n",
    "        #\"min_samples_split\": [2, 10, 100],\n",
    "    }\n",
    "    clf = GridSearchCV(rf, parameters, n_jobs=-1)\n",
    "    clf.fit(x_train, y_train)\n",
    "    return eval(clf, x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, dims):\n",
    "        super(MLP, self).__init__()\n",
    "        self.layers = []\n",
    "        for in_dim, out_dim in zip(dims[:-1], dims[1:]):\n",
    "            self.layers.append(nn.Linear(in_dim, out_dim))\n",
    "            if out_dim != dims[-1]:\n",
    "                self.layers.append(nn.ReLU())\n",
    "        self.layers = nn.Sequential(*self.layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "    def predict(self, x):\n",
    "        device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "        self.eval()\n",
    "        if type(x) == pd.DataFrame:\n",
    "            x_ = torch.from_numpy(x.values)\n",
    "        elif type(x) == np.ndarray:\n",
    "            x_ = torch.from_numpy(x)\n",
    "            \n",
    "        with torch.no_grad():\n",
    "            x_ = x_.to(device)\n",
    "            y = self.layers(x_)\n",
    "            return y.detach().cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_mlp(model, dl_train, dl_test):\n",
    "    device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    criterion = nn.MSELoss()\n",
    "    test_loss = []\n",
    "    for i in range(100):\n",
    "        iter_loss = 0\n",
    "        for x, y in dl_train:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            y_pred = model(x)\n",
    "            loss = criterion(y_pred, y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            iter_loss += loss.item()\n",
    "\n",
    "        if i % 3 == 0:\n",
    "            iter_loss = 0\n",
    "            with torch.no_grad():\n",
    "                for x, y in dl_test:\n",
    "                    x, y = x.to(device), y.to(device)\n",
    "                    y_pred = model(x)\n",
    "                    loss = criterion(y_pred, y)\n",
    "                    iter_loss += loss.item()\n",
    "                test_loss.append(iter_loss)\n",
    "\n",
    "            if i > 10 and test_loss[-1] > test_loss[-2]:\n",
    "                break        \n",
    "\n",
    "def grid_search_mlp(x_train, y_train, x_test, y_test):\n",
    "    device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "    idx_train_, idx_val = train_test_split(np.arange(x_train.shape[0]), test_size = 0.2, random_state = 0)\n",
    "    x_val_, y_val_ = x_train.values[idx_val, :], y_train[idx_val]\n",
    "    x_train_, y_train_ = x_train.values[idx_train_, :], y_train[idx_train_]\n",
    "    x_test_, y_test_ = x_test.values, y_test\n",
    "    scaler = StandardScaler()\n",
    "    x_train_ = scaler.fit_transform(x_train_)\n",
    "    x_val_ = scaler.transform(x_val_)\n",
    "    x_test_ = scaler.transform(x_test_)\n",
    "    dl_train_ = DataLoader(TensorDataset(torch.tensor(x_train_), torch.tensor(y_train_.reshape(-1, 1))), batch_size = 128)\n",
    "    dl_val = DataLoader(TensorDataset(torch.tensor(x_val_), torch.tensor(y_val_).reshape(-1, 1)), batch_size = 128)\n",
    "\n",
    "    best_r2 = -np.inf\n",
    "    best_model = None\n",
    "    for dims in [[x_train.shape[1], 64, 32, 1], [x_train.shape[1], 64, 256, 32, 1], [x_train.shape[1], 64, 512, 128, 1]]:\n",
    "        model_1 = MLP(dims)\n",
    "        model_1.to(device, dtype = torch.double)\n",
    "        train_mlp(model_1, dl_train_, dl_val)\n",
    "        r2_train, r2_test = eval(model_1, x_train_, y_train_, x_val_, y_val_)\n",
    "\n",
    "        if r2_test > best_r2:\n",
    "            best_r2 = r2_test\n",
    "            best_model = model_1\n",
    "    \n",
    "    return eval(best_model, x_train_, y_train_, x_test_, y_test_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_train, idx_test = train_test_split(np.arange(blocks_df.shape[0]), test_size = 0.2, random_state = 0)\n",
    "df_results = []\n",
    "for method in [\"count\", \"fraction\", \"fraction_coords\", \"distance\", \"distance_coords\"]:\n",
    "    x = get_x(method)\n",
    "    x_train, x_test = x.loc[idx_train, :], x.loc[idx_test, :]\n",
    "    for target in [\"mhi\", \"ed_attain\", \"density\"]:\n",
    "        y_train, y_test = blocks_df[target].values[idx_train], blocks_df[target].values[idx_test] \n",
    "        \n",
    "        for regression in [\"mlp\", \"rf\"]:\n",
    "            if regression == \"rf\":\n",
    "                r2_train, r2_test = grid_search_rf(x_train, y_train, x_test, y_test)\n",
    "            elif regression == \"mlp\":\n",
    "                r2_train, r2_test = grid_search_mlp(x_train, y_train, x_test, y_test)\n",
    "\n",
    "            print(f\"method: {method}, target: {target}, regression: {regression}, r2_train: {r2_train:.2f}, r2_test: {r2_test:.2f}\")\n",
    "            df_results.append([method, target, regression, r2_train, r2_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>target</th>\n",
       "      <th>regression</th>\n",
       "      <th>r2_train</th>\n",
       "      <th>r2_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>fraction_coords</td>\n",
       "      <td>density</td>\n",
       "      <td>rf</td>\n",
       "      <td>0.846018</td>\n",
       "      <td>0.762669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>fraction_coords</td>\n",
       "      <td>ed_attain</td>\n",
       "      <td>rf</td>\n",
       "      <td>0.882434</td>\n",
       "      <td>0.564365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>fraction_coords</td>\n",
       "      <td>mhi</td>\n",
       "      <td>rf</td>\n",
       "      <td>0.855794</td>\n",
       "      <td>0.412117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             method     target regression  r2_train   r2_test\n",
       "17  fraction_coords    density         rf  0.846018  0.762669\n",
       "15  fraction_coords  ed_attain         rf  0.882434  0.564365\n",
       "13  fraction_coords        mhi         rf  0.855794  0.412117"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    df_results, \n",
    "    columns = [\"method\", \"target\", \"regression\", \"r2_train\", \"r2_test\"]\n",
    ").sort_values(\"r2_test\", ascending = False).groupby([\"target\"]).head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>target</th>\n",
       "      <th>regression</th>\n",
       "      <th>r2_train</th>\n",
       "      <th>r2_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>distance</td>\n",
       "      <td>density</td>\n",
       "      <td>rf</td>\n",
       "      <td>0.854550</td>\n",
       "      <td>0.725477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>distance</td>\n",
       "      <td>ed_attain</td>\n",
       "      <td>mlp</td>\n",
       "      <td>0.335202</td>\n",
       "      <td>0.233670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>distance</td>\n",
       "      <td>mhi</td>\n",
       "      <td>rf</td>\n",
       "      <td>0.839111</td>\n",
       "      <td>0.178135</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      method     target regression  r2_train   r2_test\n",
       "17  distance    density         rf  0.854550  0.725477\n",
       "14  distance  ed_attain        mlp  0.335202  0.233670\n",
       "13  distance        mhi         rf  0.839111  0.178135"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    [x for x in df_results if not \"coords\" in x[0]], \n",
    "    columns = [\"method\", \"target\", \"regression\", \"r2_train\", \"r2_test\"]\n",
    ").sort_values(\"r2_test\", ascending = False).groupby([\"target\"]).head(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "urban_gdp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

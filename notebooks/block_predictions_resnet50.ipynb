{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import openTSNE\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torchvision\n",
    "\n",
    "import shapely\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../scripts\")\n",
    "from data import SmallPatchesDataset, get_filenames\n",
    "from models import AutoEncoder, DEC\n",
    "\n",
    "# autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cities_used = 3\n",
    "\n",
    "# remove patches that are have small intersection with block\n",
    "intersection_threshold = 0.25\n",
    "\n",
    "# remove patches from blocks that have more than a threshold \n",
    "patches_count_max = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "blocks_df = gpd.read_file(\"../data/census_blocks_patches_v2.geojson\")\n",
    "\n",
    "# filtering to test with some blocks, selecting the cities with the biggest number of blocks\n",
    "biggest_blocks = blocks_df.groupby([\"state\", \"county\"]).agg(\"count\").reset_index().iloc[:, 0:3].sort_values(\"tract\", ascending = False).head(n_cities_used)\n",
    "blocks_df = blocks_df[(blocks_df.state.isin(biggest_blocks.state) & blocks_df.county.isin(biggest_blocks.county))]\n",
    "\n",
    "# cleaning blocks with missing data\n",
    "blocks_df = blocks_df[blocks_df.mhi > 0]\n",
    "blocks_df = blocks_df.dropna()\n",
    "blocks_df = blocks_df[blocks_df.patches_relation.apply(len) > 0]\n",
    "\n",
    "blocks_df[\"area_km2\"] = blocks_df['geometry'].to_crs({'proj':'cea'}).area / 10**6\n",
    "blocks_df[\"density\"] = blocks_df[\"pop\"] / blocks_df[\"area_km2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_patches_relation(s):\n",
    "    s = s.split(\"\\n\")\n",
    "    s = dict([x.split(\":\") for x in s])\n",
    "    filenames = []\n",
    "    data = []\n",
    "    for key, value in s.items():\n",
    "        value = value.split(\" \")\n",
    "        idx = np.array([float(v) for v in value[0].split(\",\")])\n",
    "        ratio = np.array([float(v) for v in value[1].split(\",\")])\n",
    "        idx = idx[ratio > intersection_threshold]\n",
    "        ratio = ratio[ratio > intersection_threshold]\n",
    "        for i in range(len(idx)):\n",
    "            data.append([idx[i], ratio[i]])\n",
    "            filenames.append(key)\n",
    "    data = np.array(data)\n",
    "    if len(filenames) > patches_count_max:\n",
    "        selected = np.random.choice(\n",
    "            len(filenames),\n",
    "            size=patches_count_max,\n",
    "            replace=False,\n",
    "            p=data[:, 1] / data[:, 1].sum(),\n",
    "        )\n",
    "        data = data[selected, :]\n",
    "        filenames = [filenames[i] for i in selected]\n",
    "    return [filenames, data]\n",
    "\n",
    "blocks_df[\"clean_patches_relation\"] = blocks_df.patches_relation.apply(\n",
    "    clean_patches_relation\n",
    ")\n",
    "blocks_df[\"n_patches\"] = blocks_df[\"clean_patches_relation\"].apply(\n",
    "    lambda x: x[1].shape[0]\n",
    ")\n",
    "blocks_df = blocks_df[blocks_df.n_patches > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "blocks_df = blocks_df.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique patches: 374061\n"
     ]
    }
   ],
   "source": [
    "patches_blocks = {}\n",
    "for i, row in blocks_df.iterrows():\n",
    "    relation_list = row[\"patches_relation\"].strip(\" \").split(\" \")\n",
    "    relation_list = [x.split(\";\") for x in relation_list]\n",
    "    relation_list = row[\"clean_patches_relation\"][0]\n",
    "    idx = row[\"clean_patches_relation\"][1][:, 0]\n",
    "    files = [f\"{relation_list[j]} {int(idx[j])}\" for j in range(len(relation_list))]\n",
    "    for file in files:\n",
    "        if file in patches_blocks.keys():\n",
    "            patches_blocks[file].append(i)\n",
    "        else:\n",
    "            patches_blocks[file] = [i]\n",
    "print(f\"Number of unique patches: {len(patches_blocks.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_resnet50 = torchvision.models.resnet50(weights = \"DEFAULT\")\n",
    "model_resnet50 = nn.Sequential(*(list(model_resnet50.children())[:-1] + [nn.Flatten()]))\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_resnet50 = model_resnet50.to(device)\n",
    "\n",
    "filenames = list(patches_blocks.keys())\n",
    "filenames = np.random.choice(filenames, size = 200000, replace = False)\n",
    "dataset = SmallPatchesDataset(filenames, resize = (224, 224))\n",
    "dl = torch.utils.data.DataLoader(dataset, batch_size = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/667 [00:00<?, ?it/s]/home/giovani/miniconda3/envs/urban_gdp/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 667/667 [13:27<00:00,  1.21s/it]\n"
     ]
    }
   ],
   "source": [
    "embeddings = []\n",
    "with torch.no_grad():\n",
    "    for x in tqdm(dl):\n",
    "        x = x.to(device)\n",
    "        embeddings.append(model_resnet50(x).squeeze().cpu().numpy())\n",
    "embeddings = np.concatenate(embeddings, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/giovani/miniconda3/envs/urban_gdp/lib/python3.9/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "embeddings_proj = openTSNE.TSNE(\n",
    "    initialization=\"pca\",\n",
    "    perplexity = 250,\n",
    "    #exaggeration = 4,\n",
    "    metric = \"cosine\",\n",
    "    n_jobs=32\n",
    ").fit(embeddings[:50000, :])\n",
    "embeddings_proj = embeddings_proj.prepare_partial(embeddings)\n",
    "kmeans = KMeans(n_clusters = 30, random_state = 0).fit(embeddings_proj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "k = 30\n",
    "latent_dim = 2048\n",
    "cluster_centers_idx = [np.argmin(np.linalg.norm(embeddings_proj - kmeans.cluster_centers_[i], axis=1))\n",
    "                       for i in range(k)]\n",
    "centroids = torch.tensor(embeddings[cluster_centers_idx, :]).to(device)\n",
    "\n",
    "model_dec = DEC(\n",
    "    n_clusters = k,\n",
    "    embedding_dim = 2048,\n",
    "    encoder = model_resnet50,\n",
    "    cluster_centers = centroids,\n",
    ")\n",
    "model_dec = model_dec.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = list(patches_blocks.keys())\n",
    "dataset = SmallPatchesDataset(filenames, resize = (224, 224))\n",
    "dl = torch.utils.data.DataLoader(dataset, batch_size = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clusters(dl, model):\n",
    "    device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "    clusters = []\n",
    "    clusters_distance = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dl):\n",
    "            batch = batch.to(device)\n",
    "            c = model(batch).detach().cpu().numpy()\n",
    "            d = model.centroids_distance(batch).detach().cpu().numpy()\n",
    "            clusters.append(c)\n",
    "            clusters_distance.append(d)\n",
    "\n",
    "    clusters = np.concatenate(clusters).argmax(axis = 1)\n",
    "    clusters_distance = np.concatenate(clusters_distance)\n",
    "    return clusters, clusters_distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1247 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/giovani/miniconda3/envs/urban_gdp/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "100%|██████████| 1247/1247 [29:37<00:00,  1.43s/it]\n"
     ]
    }
   ],
   "source": [
    "clusters, clusters_distance = get_clusters(dl, model_dec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of all methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to generate features from model output\n",
    "def count_of_patches_cluster():\n",
    "    x = np.zeros((blocks_df.shape[0], k))\n",
    "    for i, (file, cluster) in enumerate(zip(filenames, clusters)):\n",
    "        for b in patches_blocks[file]:\n",
    "            x[b, cluster] += 1\n",
    "    x = pd.DataFrame(x, columns = [f\"cluster_{i}\" for i in range(k)])\n",
    "    x = x.loc[:, x.sum(axis = 0) > 0]\n",
    "    return x\n",
    "\n",
    "def fraction_of_patches_cluster():\n",
    "    x = np.zeros((blocks_df.shape[0], k))\n",
    "    for i, (file, cluster) in enumerate(zip(filenames, clusters)):\n",
    "        for b in patches_blocks[file]:\n",
    "            x[b, cluster] += 1\n",
    "    x_sum = x.sum(axis = 1)\n",
    "    x = x / x_sum[:, None]\n",
    "    x = pd.DataFrame(x, columns = [f\"cluster_{i}\" for i in range(k)])\n",
    "    x = x.loc[:, x.sum(axis = 0) > 0]\n",
    "    x[\"count\"] = x_sum\n",
    "    return x\n",
    "\n",
    "def distance_of_patches_cluster():\n",
    "    x = np.zeros((blocks_df.shape[0], k))\n",
    "    for i, (file, distances) in enumerate(zip(filenames, clusters_distance)):\n",
    "        for b in patches_blocks[file]:\n",
    "            x[b] += distances\n",
    "    x_sum = blocks_df.n_patches.values.reshape(-1)\n",
    "    x = x / x_sum[:, None]\n",
    "    x = pd.DataFrame(x, columns = [f\"cluster_{i}\" for i in range(k)])\n",
    "    x = x.loc[:, x.sum(axis = 0) > 0]\n",
    "    x[\"count\"] = x_sum\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_x(method):\n",
    "    if method == \"count\":\n",
    "        return count_of_patches_cluster()\n",
    "    elif method == \"fraction\":\n",
    "        return fraction_of_patches_cluster()\n",
    "    elif method == \"distance\":\n",
    "        return distance_of_patches_cluster()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(clf, x_train, y_train, x_test, y_test):\n",
    "    mae_train = mean_absolute_error(y_train, clf.predict(x_train))\n",
    "    r2_train = r2_score(y_train, clf.predict(x_train))\n",
    "    \n",
    "    mae_test = mean_absolute_error(y_test, clf.predict(x_test))\n",
    "    r2_test = r2_score(y_test, clf.predict(x_test))\n",
    "    return r2_train, r2_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_rf(x_train, y_train, x_test, y_test):\n",
    "    rf = RandomForestRegressor()\n",
    "    parameters = {\n",
    "        \"n_estimators\": [10, 100, 1000],\n",
    "        \"max_depth\": [10, 100],\n",
    "        #\"min_samples_split\": [2, 10, 100],\n",
    "    }\n",
    "    clf = GridSearchCV(rf, parameters, n_jobs=-1)\n",
    "    clf.fit(x_train, y_train)\n",
    "    return eval(clf, x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, dims):\n",
    "        super(MLP, self).__init__()\n",
    "        self.layers = []\n",
    "        for in_dim, out_dim in zip(dims[:-1], dims[1:]):\n",
    "            self.layers.append(nn.Linear(in_dim, out_dim))\n",
    "            if out_dim != dims[-1]:\n",
    "                self.layers.append(nn.ReLU())\n",
    "        self.layers = nn.Sequential(*self.layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "    def predict(self, x):\n",
    "        device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "        self.eval()\n",
    "        if type(x) == pd.DataFrame:\n",
    "            x_ = torch.from_numpy(x.values)\n",
    "        elif type(x) == np.ndarray:\n",
    "            x_ = torch.from_numpy(x)\n",
    "            \n",
    "        with torch.no_grad():\n",
    "            x_ = x_.to(device)\n",
    "            y = self.layers(x_)\n",
    "            return y.detach().cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_mlp(model, dl_train, dl_test):\n",
    "    device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    criterion = nn.MSELoss()\n",
    "    test_loss = []\n",
    "    for i in range(100):\n",
    "        iter_loss = 0\n",
    "        for x, y in dl_train:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            y_pred = model(x)\n",
    "            loss = criterion(y_pred, y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            iter_loss += loss.item()\n",
    "\n",
    "        if i % 3 == 0:\n",
    "            iter_loss = 0\n",
    "            with torch.no_grad():\n",
    "                for x, y in dl_test:\n",
    "                    x, y = x.to(device), y.to(device)\n",
    "                    y_pred = model(x)\n",
    "                    loss = criterion(y_pred, y)\n",
    "                    iter_loss += loss.item()\n",
    "                test_loss.append(iter_loss)\n",
    "\n",
    "            if i > 10 and test_loss[-1] > test_loss[-2]:\n",
    "                break        \n",
    "\n",
    "def grid_search_mlp(x_train, y_train, x_test, y_test):\n",
    "    device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "    idx_train_, idx_val = train_test_split(np.arange(x_train.shape[0]), test_size = 0.2, random_state = 0)\n",
    "    x_val_, y_val_ = x_train.values[idx_val, :], y_train[idx_val]\n",
    "    x_train_, y_train_ = x_train.values[idx_train_, :], y_train[idx_train_]\n",
    "    x_test_, y_test_ = x_test.values, y_test\n",
    "    scaler = StandardScaler()\n",
    "    x_train_ = scaler.fit_transform(x_train_)\n",
    "    x_val_ = scaler.transform(x_val_)\n",
    "    x_test_ = scaler.transform(x_test_)\n",
    "    dl_train_ = DataLoader(TensorDataset(torch.tensor(x_train_), torch.tensor(y_train_.reshape(-1, 1))), batch_size = 128)\n",
    "    dl_val = DataLoader(TensorDataset(torch.tensor(x_val_), torch.tensor(y_val_).reshape(-1, 1)), batch_size = 128)\n",
    "\n",
    "    best_r2 = -np.inf\n",
    "    best_model = None\n",
    "    for dims in [[x_train.shape[1], 32, 64, 32, 1], [x_train.shape[1], 64, 256, 32, 1], [x_train.shape[1], 64, 512, 128, 1]]:\n",
    "        model_1 = MLP(dims)\n",
    "        model_1.to(device, dtype = torch.double)\n",
    "        train_mlp(model_1, dl_train_, dl_val)\n",
    "        r2_train, r2_test = eval(model_1, x_train_, y_train_, x_val_, y_val_)\n",
    "\n",
    "        if r2_test > best_r2:\n",
    "            best_r2 = r2_test\n",
    "            best_model = model_1\n",
    "    \n",
    "    return eval(model_1, x_train_, y_train_, x_test_, y_test_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method: count, target: mhi, regression: mlp, r2_train: 0.10107643343802786, r2_test: 0.04804542208160645\n",
      "method: count, target: mhi, regression: rf, r2_train: 0.29905723112348626, r2_test: 0.09965466240427368\n",
      "method: count, target: ed_attain, regression: mlp, r2_train: 0.21893694798262653, r2_test: 0.10391308175482461\n",
      "method: count, target: ed_attain, regression: rf, r2_train: 0.3220959616503398, r2_test: 0.12442416152225233\n",
      "method: count, target: pop, regression: mlp, r2_train: 0.1163760478509519, r2_test: 0.0627726086235828\n",
      "method: count, target: pop, regression: rf, r2_train: 0.4125801020092036, r2_test: 0.07715493208584012\n",
      "method: fraction, target: mhi, regression: mlp, r2_train: 0.10796148356469182, r2_test: 0.05449217599635159\n",
      "method: fraction, target: mhi, regression: rf, r2_train: 0.3273182912747492, r2_test: 0.11100192079732263\n",
      "method: fraction, target: ed_attain, regression: mlp, r2_train: 0.19166412348926554, r2_test: 0.09648794377830927\n",
      "method: fraction, target: ed_attain, regression: rf, r2_train: 0.30281988405915106, r2_test: 0.13425129226502486\n",
      "method: fraction, target: pop, regression: mlp, r2_train: 0.11790157868949269, r2_test: 0.06704089742860564\n",
      "method: fraction, target: pop, regression: rf, r2_train: 0.4017702910856076, r2_test: 0.07393507157741308\n",
      "method: distance, target: mhi, regression: mlp, r2_train: 0.11805483631416935, r2_test: 0.11422588099045494\n",
      "method: distance, target: mhi, regression: rf, r2_train: 0.35344045346535247, r2_test: 0.09301055121436208\n",
      "method: distance, target: ed_attain, regression: mlp, r2_train: 0.22145498999626623, r2_test: 0.18966925220026443\n",
      "method: distance, target: ed_attain, regression: rf, r2_train: 0.8882525303580979, r2_test: 0.1667400573419815\n",
      "method: distance, target: pop, regression: mlp, r2_train: 0.10186735981129458, r2_test: 0.0977414267404324\n",
      "method: distance, target: pop, regression: rf, r2_train: 0.4255822226450452, r2_test: 0.07424858221441011\n"
     ]
    }
   ],
   "source": [
    "idx_train, idx_test = train_test_split(np.arange(blocks_df.shape[0]), test_size = 0.2, random_state = 0)\n",
    "df_results = []\n",
    "for method in [\"count\", \"fraction\", \"distance\"]:\n",
    "    x = get_x(method)\n",
    "    x_train, x_test = x.loc[idx_train, :], x.loc[idx_test, :]\n",
    "    for target in [\"mhi\", \"ed_attain\", \"pop\"]:\n",
    "        y_train, y_test = blocks_df[target].values[idx_train], blocks_df[target].values[idx_test] \n",
    "        \n",
    "        for regression in [\"mlp\", \"rf\"]:\n",
    "            if regression == \"rf\":\n",
    "                r2_train, r2_test = grid_search_rf(x_train, y_train, x_test, y_test)\n",
    "            elif regression == \"mlp\":\n",
    "                r2_train, r2_test = grid_search_mlp(x_train, y_train, x_test, y_test)\n",
    "\n",
    "            print(f\"method: {method}, target: {target}, regression: {regression}, r2_train: {r2_train:.2f}, r2_test: {r2_test:.2f}\")\n",
    "            df_results.append([method, target, regression, r2_train, r2_test])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "urban_gdp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
